{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "Activate the project environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"v0.9.0\", \"/home/jupyter/ECON628_local/MetricProject_test/.projects/QuantEconLectureAllPackages-v0.9.0\")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using InstantiateFromURL\n",
    "activate_github(\"QuantEcon/QuantEconLectureAllPackages\", tag = \"v0.9.0\") # activate the QuantEcon environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, Statistics, Compat, Parameters, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete choice\n",
    "\n",
    "In this exercise I have to create a data set of students, schools and distances. The student must choose between the schools he have in his menu taking in account the distance. With the data in hands, the exercise demand to estimate the parameters of the data generator process assuming two different hypothesis about the distribution of the unobservable component of the utility: (1) $\\epsilon$ is normal; (2) $\\epsilon$ is T1EV. The true $\\epsilon$ is normal, however, we do not have a formula for the expected utility when $\\epsilon$ is normal as we have in the T1EV case. So, in the first case we have a source of error associated to the fact we have to approximate the expectation and in second case we will have a source of error associated to the fact that we are not using the correct distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=500; #number of students\n",
    "numSch=5; #number of schools\n",
    "seed = 0;\n",
    "μ = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the data\n",
    "Main parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(seed+1); #fixing the seed\n",
    "δ    = randn(numSch,1) .+ μ; #generating the parameter deltas (mean utility of each school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.282549830161864"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = abs.(randn(N,numSch)); #generating the observable distance\n",
    "γ    = 1.2;\n",
    "σ    = sqrt((pi^2)/6.0) #I am fixing the variance of the normal to be equal of the T1EV(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw the utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(seed+2); \n",
    "ϵ=σ*randn(N,numSch);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the utilities in a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "util = repeat(δ',N,1) .- γ*dist .+ ϵ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's introduce a variation in the menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "menuSize = zeros(Int64,N,1);\n",
    "choice   = zeros(Int64,N,1);\n",
    "menu     = zeros(Bool, N,numSch);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(seed+3);\n",
    "for i=1:N\n",
    "    #Number of schools in the menu\n",
    "    menuSize[i]=rand(DiscreteUniform(1,numSch-1)) + 1; \n",
    "    # Generate a random integer uniformaly distributed between 1 and (numSch-1)\n",
    "    # I add 1 to assure that they will have at least 2 options\n",
    "    \n",
    "    #Identity of schools in the menu\n",
    "    temp=randperm(numSch); \n",
    "    # return a random permutation of integers between 1 and NumSch\n",
    "    \n",
    "    for j=1:numSch\n",
    "        if any(temp[1:menuSize[i]].==j) \n",
    "            # any() returns equal 1 if any element of the array is non-zero\n",
    "            # 1:menuSize[i] is the menu of individual i\n",
    "            # Thus I will put one in the matrix menu when the i have the\n",
    "            # option j available\n",
    "            menu[i,j]=true;\n",
    "        end\n",
    "    end   \n",
    "    \n",
    "    #Choose the school that provides highest utility\n",
    "    choice[i]=findall(util[i,:].== findmax(util[i,menu[i,:]])[1])[1]; # I am assuming no ties!\n",
    "    # I am returning the position of the option with the highest utility\n",
    "    # that is available in the menu\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the likelihood funtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assume $\\epsilon \\sim T1EV(0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dcobj_t1ev (generic function with 1 method)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function dcobj_t1ev(x,choice,dist,N,numSch,menu)\n",
    "    δ = [x[1:numSch-1];0.0];\n",
    "    γ = x[numSch];\n",
    "    v = exp.(δ'.-γ*dist).*menu;\n",
    "    PredProb = v ./ repeat(sum(v,dims=2),1,numSch);\n",
    "    chocProb = [PredProb[i,choice[i]] for i in 1:N];\n",
    "    objVal   =-sum(log, chocProb);\n",
    "    \n",
    "    return objVal\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrue =     [δ[1:numSch-1].-δ[numSch];γ];\n",
    "xinit = 0.9*[δ[1:numSch-1].-δ[numSch];γ];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the likelihood function first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457.8313102634201"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcobj_t1ev(xinit,choice,dist,N,numSch,menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim\n",
    "using Optim: converged, maximum, maximizer, minimizer, iterations #some extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Nelder-Mead\n",
       " * Starting Point: [1.022683355031803,1.0992805399614345, ...]\n",
       " * Minimizer: [1.5078846889211288,1.5115568978947496, ...]\n",
       " * Minimum: 4.472344e+02\n",
       " * Iterations: 168\n",
       " * Convergence: true\n",
       "   *  √(Σ(yᵢ-ȳ)²)/n < 1.0e-08: true\n",
       "   * Reached Maximum Number of Iterations: false\n",
       " * Objective Calls: 299"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = optimize(x -> dcobj_t1ev(x,choice,dist,N,numSch, menu), xinit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum = 447.23443515255144 with argmin = [1.50788, 1.51156, 0.333182, 0.877001, 1.56654] in 168 iterations\n"
     ]
    }
   ],
   "source": [
    "println(\"minimum = $(results.minimum) with argmin = $(results.minimizer) in $(results.iterations) iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(θhat = [1.50788, 1.51156, 0.333182, 0.877001, 1.56654], θtrue = [1.13631, 1.22142, 0.241392, 0.828582, 1.2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = (θhat = results.minimizer, θtrue = xtrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets assume that  $\\epsilon \\sim N(0,\\pi^2 /6)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we have to simulate the distribution in order to get the likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dcobj_normal (generic function with 2 methods)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function dcobj_normal(x,choice,dist,N,numSch, menu,seed)\n",
    "    δ = [x[1:numSch-1];0.0];\n",
    "    γ = x[numSch];\n",
    "    σ = sqrt((pi^2)/6);\n",
    "    \n",
    "    # Draw the epsilon to simulate the choice probabilities\n",
    "    Random.seed!(seed+4); \n",
    "    numDraws=numSch*20;\n",
    "    ϵsim = σ*randn(numDraws,numSch, N);\n",
    "    \n",
    "    #Compute the simulated utilities and the choice for each draws\n",
    "    # Note that here we need only the probability of the best option, the other\n",
    "    # probabilities do not matter here\n",
    "    simChoice = zeros(Int64,numDraws,1);\n",
    "    simProb   = zeros(N,1);\n",
    "    \n",
    "    for i=1:N\n",
    "        simUtil = repeat(δ',numDraws,1) - γ*repeat(dist[i,:]',numDraws,1) + ϵsim[:,:,i];\n",
    "        for k=1:numDraws\n",
    "            simChoice[k]=findall(simUtil[k,:].== findmax(simUtil[k,menu[i,:]])[1])[1];\n",
    "        end\n",
    "\n",
    "        simProb[i] = sum(simChoice.==choice[i])/numDraws;\n",
    "\n",
    "    end\n",
    "    \n",
    "    objVal   =-sum(log, simProb);\n",
    "    \n",
    "    return objVal\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the new likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462.28047338647497"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcobj_normal(xinit,choice,dist,N,numSch,menu,seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the optmizer again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Nelder-Mead\n",
       " * Starting Point: [1.022683355031803,1.0992805399614345, ...]\n",
       " * Minimizer: [1.182000655963147,1.3110638280973923, ...]\n",
       " * Minimum: 4.570797e+02\n",
       " * Iterations: 114\n",
       " * Convergence: true\n",
       "   *  √(Σ(yᵢ-ȳ)²)/n < 1.0e-08: true\n",
       "   * Reached Maximum Number of Iterations: false\n",
       " * Objective Calls: 277"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = optimize(x -> dcobj_normal(x,choice,dist,N,numSch,menu,seed), xinit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(θhat = [1.182, 1.31106, 0.090613, 0.73456, 1.33146], θtrue = [1.13631, 1.22142, 0.241392, 0.828582, 1.2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison2 = (θhat = results2.minimizer, θtrue = xtrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×3 Array{Float64,2}:\n",
       " 1.13631   1.50788   1.182   \n",
       " 1.22142   1.51156   1.31106 \n",
       " 0.241392  0.333182  0.090613\n",
       " 0.828582  0.877001  0.73456 \n",
       " 1.2       1.56654   1.33146 "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "θtrue = xtrue;\n",
    "θhat_t1ev = results.minimizer;\n",
    "θhat_normal = results2.minimizer;\n",
    "[θtrue θhat_t1ev θhat_normal]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed in the beginning, both estimatives have noise. However, the estimative assuming T1EV is considerably faster than the one assuming normal unobservables. We would have to perform some Monte Carlo simulation to check the consistency"
   ]
  }
 ],
 "metadata": {
  "filename": "introduction_to_types.rst",
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.1"
  },
  "title": "Introduction to Types and Generic Programming"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
